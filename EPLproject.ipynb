{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d5dc7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "55660236",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"MatchesAndRatings.csv\")\n",
    "test = pd.read_csv(\"testCSV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e8728f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeScore</th>\n",
       "      <th>AwayScore</th>\n",
       "      <th>Time</th>\n",
       "      <th>Ref</th>\n",
       "      <th>HomeForm</th>\n",
       "      <th>AwayForm</th>\n",
       "      <th>HomeMissingPlayers</th>\n",
       "      <th>AwayMissingPlayers</th>\n",
       "      <th>Round</th>\n",
       "      <th>GD</th>\n",
       "      <th>HomeAtt</th>\n",
       "      <th>HomeDef</th>\n",
       "      <th>HomeMid</th>\n",
       "      <th>HomeOVR</th>\n",
       "      <th>AwayAtt</th>\n",
       "      <th>AwayDef</th>\n",
       "      <th>AwayMid</th>\n",
       "      <th>AwayOVR</th>\n",
       "      <th>y</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Round_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-22 22:00:00</td>\n",
       "      <td>Andre Marriner</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Premier League Round 37 2022/2023</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Man City</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-24 22:00:00</td>\n",
       "      <td>Simon Hooper</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Premier League Round 32 2022/2023</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-25 22:00:00</td>\n",
       "      <td>Stuart Attwell</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Premier League Round 32 2022/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-28 18:30:00</td>\n",
       "      <td>Andre Marriner</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Premier League Round 38 2022/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-28 18:30:00</td>\n",
       "      <td>David Coote</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Premier League Round 38 2022/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0     HomeTeam   AwayTeam  HomeScore  AwayScore                 Time             Ref  HomeForm  AwayForm  HomeMissingPlayers  AwayMissingPlayers                              Round  GD  HomeAtt  HomeDef  HomeMid  HomeOVR  AwayAtt  AwayDef  AwayMid  AwayOVR  y  Year  Month  Day  Round_Number\n",
       "0             0           0    Newcastle  Leicester          0          0  2023-05-22 22:00:00  Andre Marriner        10         5                   6                   6  Premier League Round 37 2022/2023   0       78       79       76       78       79       78       79       79  0  2023      5   22            37\n",
       "1             1           1     Brighton   Man City          1          1  2023-05-24 22:00:00    Simon Hooper         9        13                   6                   5  Premier League Round 32 2022/2023   0       76       77       75       76       85       86       86       85  0  2023      5   24            32\n",
       "2             2           2   Man United    Chelsea          4          1  2023-05-25 22:00:00  Stuart Attwell         9         4                   5                   8  Premier League Round 32 2022/2023   3       81       80       82       82       83       83       86       84  1  2023      5   25            32\n",
       "3             3           3      Arsenal     Wolves          5          0  2023-05-28 18:30:00  Andre Marriner         6         7                   5                   2  Premier League Round 38 2022/2023   5       83       79       80       80       79       77       79       78  1  2023      5   28            38\n",
       "4             4           4  Aston Villa   Brighton          2          1  2023-05-28 18:30:00     David Coote         7         7                   2                   0  Premier League Round 38 2022/2023   1       79       80       78       79       76       77       75       76  1  2023      5   28            38"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c7cddf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = ['Unnamed: 0.1', 'Unnamed: 0', 'HomeScore', 'AwayScore', 'y', 'Year', 'Day', 'Time', 'GD', 'Round']\n",
    "y_train = train['y'].copy()\n",
    "y_test = test['y'].copy()\n",
    "\n",
    "Xtrain = train.drop(dropped_columns, axis=1)\n",
    "Xtest = test.drop(dropped_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ddd7dd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUI0lEQVR4nO3dfbRddX3n8fcHQkcQKrJyjZAEr3XiAz4BE5Qp06kttioRgjNrKKyi1LqaPmArM6xlI3VV1sxiVmaNBWsd6aBSoEWUilQU7BCoU8dWxYQiT4GSJcEkBBJbMQgIBr/zx9l3c5rcJCcP5+yT3PdrrbPu3r+z9z6fPNz7ufvh7JOqQpIkgAO6DiBJGh+WgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgvZbSdYkefNWY7+W5GsjznFhkh8n+WHf4/2jzCANalbXAaQZ4rNVdfburpxkVlVt2ZuBpOm4p6AZK8mrkvzfJI8luSfJaX3PXZHk40m+3Pxm/3dJXpzkI0m+n+S+JMf1LX9UkuuSbEryYJLfGzDDac1rP9ZkeVXfc2uS/H6SO4EnkvzrJJXk3UnWNjl+K8kJSe5stvGxvfqXpBnHUtCMlOQg4IvAzcCLgN8Frk7yir7FzgA+CMwGnga+DtzezH8OuLjZ1gHNtr4NzAVOBs5L8padZHg5cA1wHjAB3AR8MclP9S12FrAIOByY2lN4I7AA+BXgI8AfAG8GXg2ckeTnd+GvQvoXLAXt7/6q+Q36sSSPAR9vxk8EDgWWVdUzVfU3wJfo/RCecn1VrayqHwHXAz+qqquq6lngs8DUnsIJwERV/ddmW98BPgGc2betM/pzJDmK3g/1G6tqeVX9GPgwcDDws33rfbSq1lbVU31j/62qflRVNwNPANdU1caqWg/8v75c0i6zFLS/O72qDp96AL/TjB8FrK2qn/Qt+xC93/SnPNo3/dQ084c20y8BjtqqfC4A5vQtf21/jqp6uMnw0NQCTZa1W2VYO82fadBc0i7zRLNmqoeB+UkO6CuGo4F/3I1trQUerKoFu5HhtVMzSQLMB9b3LeNtjDVS7ilopvom8CTw/iQHJXkTcCrwmd3Y1m3A481J4YOTHJjkNUlO2Ml61wKLkpzcnOM4n965i7/fjQzSXmEpaEaqqmfolcDbgO/RO9fwrqq6bze29SzwduBY4MFme58EXrCT9e4Hzgb+pFnnVODUJpvUifghO5KkKe4pSJJaloIkqWUpSJJaloIkqbVPv09h9uzZNTk52XUMSdqnrFy58ntVNTHdc/t0KUxOTrJixYquY0jSPiXJQ9t7zsNHkqSWpSBJalkKkqSWpSBJalkKkqSWpSBJalkKkqSWpSBJalkKkqTWPv2OZmlnJpfe2Nlrr1m2qLPXlnaXewqSpJalIElqWQqSpJalIElqWQqSpJalIElqWQqSpNbQSiHJ/CRfSXJvknuSvK8ZvzDJ+iR3NI9T+tb5QJLVSe5P8pZhZZMkTW+Yb17bApxfVbcnOQxYmWR589wlVfXh/oWTHAOcCbwaOAq4JcnLq+rZIWaUJPUZ2p5CVW2oqtub6ceBVcDcHayyGPhMVT1dVQ8Cq4E3DCufJGlbIzmnkGQSOA74ZjP03iR3Jrk8yQubsbnA2r7V1jFNiSRZkmRFkhWbNm0aZmxJmnGGXgpJDgWuA86rqs3ApcDLgGOBDcAf7cr2quqyqlpYVQsnJib2dlxJmtGGWgpJDqJXCFdX1ecBqurRqnq2qn4CfILnDhGtB+b3rT6vGZMkjcgwrz4K8ClgVVVd3Dd+ZN9i7wDubqZvAM5M8q+SvBRYANw2rHySpG0N8+qjk4B3AncluaMZuwA4K8mxQAFrgN8EqKp7klwL3EvvyqVzvfJIkkZraKVQVV8DMs1TN+1gnYuAi4aVSZK0Y76jWZLUshQkSS0/jlPaz3T1EaR+/Oj+wT0FSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVLLUpAktSwFSVJraKWQZH6SryS5N8k9Sd7XjB+RZHmSB5qvL2zGk+SjSVYnuTPJ8cPKJkma3jD3FLYA51fVMcCJwLlJjgGWArdW1QLg1mYe4G3AguaxBLh0iNkkSdMYWilU1Yaqur2ZfhxYBcwFFgNXNotdCZzeTC8GrqqebwCHJzlyWPkkSdsayTmFJJPAccA3gTlVtaF56hFgTjM9F1jbt9q6ZmzrbS1JsiLJik2bNg0vtCTNQEMvhSSHAtcB51XV5v7nqqqA2pXtVdVlVbWwqhZOTEzsxaSSpKGWQpKD6BXC1VX1+Wb40anDQs3Xjc34emB+3+rzmjFJ0ogM8+qjAJ8CVlXVxX1P3QCc00yfA3yhb/xdzVVIJwI/6DvMJEkagVlD3PZJwDuBu5Lc0YxdACwDrk3yHuAh4IzmuZuAU4DVwJPAu4eYTZI0jaGVQlV9Dch2nj55muULOHdYeSRJO+c7miVJLUtBktSyFCRJLUtBktSyFCRJrWFekqoxM7n0xs5ee82yRZ29tqTBuacgSWpZCpKklqUgSWpZCpKklqUgSWpZCpKklqUgSWpZCpKklqUgSWpZCpKklqUgSWpZCpKklqUgSWoNVApJXjvsIJKk7g26p/DxJLcl+Z0kLxhqIklSZwYqhar6OeBXgfnAyiSfTvJLQ00mSRq5gc8pVNUDwAeB3wd+HvhokvuS/IdhhZMkjdag5xRel+QSYBXwi8CpVfWqZvqSIeaTJI3QoB/H+SfAJ4ELquqpqcGqejjJB4eSTJI0coOWwiLgqap6FiDJAcDzqurJqvrzoaWTJI3UoOcUbgEO7ps/pBmTJO1HBi2F51XVD6dmmulDhhNJktSVQUvhiSTHT80k+TfAUztYXpK0Dxr0nMJ5wF8meRgI8GLgV4YVSpLUjUHfvPYt4JXAbwO/BbyqqlbuaJ0klyfZmOTuvrELk6xPckfzOKXvuQ8kWZ3k/iRv2b0/jiRpTwy6pwBwAjDZrHN8Eqrqqh0sfwXwMWDrZS6pqg/3DyQ5BjgTeDVwFHBLkpdPXe0kSRqNgUohyZ8DLwPuAKZ+UBfb/sBvVdVXk0wOmGMx8Jmqehp4MMlq4A3A1wdcX5K0Fwy6p7AQOKaqai+85nuTvAtYAZxfVd8H5gLf6FtmXTO2jSRLgCUARx999F6II0maMujVR3fTO7m8py6lt8dxLLAB+KNd3UBVXVZVC6tq4cTExF6IJEmaMuiewmzg3iS3AU9PDVbVabvyYlX16NR0kk8AX2pm19O7A+uUec2YJGmEBi2FC/fGiyU5sqo2NLPvoLcHAnAD8OkkF9M70bwAuG1vvKYkaXADlUJV/W2SlwALquqWJIcAB+5onSTXAG8CZidZB3wIeFOSY+mdpF4D/Gaz/XuSXAvcC2wBzvXKI0kavUGvPvoNeid3j6B3TmAu8KfAydtbp6rOmmb4UztY/iLgokHySJKGY9ATzecCJwGbof3AnRcNK5QkqRuDlsLTVfXM1EySWfQOAUmS9iODlsLfJrkAOLj5bOa/BL44vFiSpC4MWgpLgU3AXfRODt9E7/OaJUn7kUGvPvoJ8InmIUnaTw169dGDTHMOoap+Zq8nkiR1ZlfufTTlecB/ond5qiRpPzLo5yn8U99jfVV9BFg03GiSpFEb9PDR8X2zB9Dbc9iVz2KQJO0DBv3B3n830y30blFxxl5PI0nq1KBXH/3CsINIkro36OGj/7Kj56vq4r0TR5LUpV25+ugEere4BjiV3q2tHxhGKElSNwYthXnA8VX1OECSC4Ebq+rsYQWTJI3eoLe5mAM80zf/TDMmSdqPDLqncBVwW5Lrm/nTgSuHkkiS1JlBrz66KMmXgZ9rht5dVf8wvFiSpC4MevgI4BBgc1X9MbAuyUuHlEmS1JFBL0n9EL0rkF4B/BlwEPAX9D6NTZI6Nbn0xk5ed82y/e9uP4PuKbwDOA14AqCqHgYOG1YoSVI3Bi2FZ6qqaG6fneT5w4skSerKoKVwbZL/DRye5DeAW/ADdyRpv7PTcwpJAnwWeCWwmd55hT+squVDziZJGrGdlkJVVZKbquq1gEUgSfuxQQ8f3Z7khKEmkSR1btB3NL8RODvJGnpXIIXeTsTrhhVMkjR6OyyFJEdX1XeBt4wojySpQzvbU/grendHfSjJdVX1H0eQSZLUkZ2dU0jf9M8MM4gkqXs7K4XazrQkaT+0s1J4fZLNSR4HXtdMb07yeJLNO1oxyeVJNia5u2/siCTLkzzQfH1hM54kH02yOsmdSY7f8z+aJGlX7bAUqurAqvrpqjqsqmY101PzP72TbV8BvHWrsaXArVW1ALi1mQd4G7CgeSwBLt3VP4gkac/tyq2zd0lVfRX4562GF/Pch/NcSe/DeqbGr6qeb9C7ncaRw8omSZre0EphO+ZU1YZm+hGe+0jPucDavuXWNWPbSLIkyYokKzZt2jS8pJI0A426FFr9d13dxfUuq6qFVbVwYmJiCMkkaeYadSk8OnVYqPm6sRlfD8zvW25eMyZJGqFRl8INwDnN9DnAF/rG39VchXQi8IO+w0ySpBEZ9N5HuyzJNcCbgNlJ1gEfApbR+2yG9wAPAWc0i98EnAKsBp4E3j2sXJKk7RtaKVTVWdt56uRpli3g3GFlkSQNprMTzZKk8WMpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqTW0u6RK/SaX3th1BEkDcE9BktRyT0EaEveOtC+asaXQ5TfsmmWLOnttSdoRDx9JklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqd3CU1yRrgceBZYEtVLUxyBPBZYBJYA5xRVd/vIp8kzVRd7in8QlUdW1ULm/mlwK1VtQC4tZmXJI3QOB0+Wgxc2UxfCZzeXRRJmpm6KoUCbk6yMsmSZmxOVW1oph8B5nQTTZJmrq4+ee3fVdX6JC8Clie5r//JqqokNd2KTYksATj66KOHn1SSZpBO9hSqan3zdSNwPfAG4NEkRwI0XzduZ93LqmphVS2cmJgYVWRJmhFGXgpJnp/ksKlp4JeBu4EbgHOaxc4BvjDqbJI003Vx+GgOcH2Sqdf/dFX9dZJvAdcmeQ/wEHBGB9kkaUYbeSlU1XeA108z/k/AyaPOI0l6zjhdkipJ6lhXVx9J0j5vcumNnb32mmWLhrJd9xQkSS1LQZLUshQkSS3PKXSgy+OQkrQj7ilIklqWgiSpZSlIklqWgiSp5YlmSXuFF1DsH9xTkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUmvsSiHJW5Pcn2R1kqVd55GkmWSsSiHJgcD/At4GHAOcleSYblNJ0swxVqUAvAFYXVXfqapngM8AizvOJEkzxqyuA2xlLrC2b34d8Mb+BZIsAZY0sz9Mcv9uvtZs4Hu7ue6omHHPjXs+GP+M454Pxj/jXs+X/7FHq79ke0+MWynsVFVdBly2p9tJsqKqFu6FSENjxj037vlg/DOOez4Y/4zjnq/fuB0+Wg/M75uf14xJkkZg3ErhW8CCJC9N8lPAmcANHWeSpBljrA4fVdWWJO8F/g9wIHB5Vd0zpJfb40NQI2DGPTfu+WD8M457Phj/jOOer5Wq6jqDJGlMjNvhI0lShywFSVJrRpbCuN9KI8n8JF9Jcm+Se5K8r+tM00lyYJJ/SPKlrrNMJ8nhST6X5L4kq5L8264z9Uvyn5t/37uTXJPkeWOQ6fIkG5Pc3Td2RJLlSR5ovr5wDDP+z+bf+c4k1yc5fJzy9T13fpJKMruLbIOYcaWwj9xKYwtwflUdA5wInDuGGQHeB6zqOsQO/DHw11X1SuD1jFHWJHOB3wMWVtVr6F1YcWa3qQC4AnjrVmNLgVuragFwazPfpSvYNuNy4DVV9TrgH4EPjDpUnyvYNh9J5gO/DHx31IF2xYwrBfaBW2lU1Yaqur2ZfpzeD7O53ab6l5LMAxYBn+w6y3SSvAD498CnAKrqmap6rNNQ25oFHJxkFnAI8HDHeaiqrwL/vNXwYuDKZvpK4PRRZtradBmr6uaq2tLMfoPee5w6sZ2/Q4BLgPcDY311z0wshelupTFWP3D7JZkEjgO+2XGUrX2E3n/wn3ScY3teCmwC/qw5xPXJJM/vOtSUqloPfJjeb40bgB9U1c3dptquOVW1oZl+BJjTZZgB/Drw5a5D9EuyGFhfVd/uOsvOzMRS2GckORS4DjivqjZ3nWdKkrcDG6tqZddZdmAWcDxwaVUdBzxB94c9Ws1x+cX0yuso4PlJzu421c5V7xr2sf1NN8kf0Dv8enXXWaYkOQS4APjDrrMMYiaWwj5xK40kB9ErhKur6vNd59nKScBpSdbQO/z2i0n+ottI21gHrKuqqT2sz9EriXHxZuDBqtpUVT8GPg/8bMeZtufRJEcCNF83dpxnWkl+DXg78Ks1Xm/Aehm98v928z0zD7g9yYs7TbUdM7EUxv5WGklC71j4qqq6uOs8W6uqD1TVvKqapPf39zdVNVa/5VbVI8DaJK9ohk4G7u0w0ta+C5yY5JDm3/tkxuhE+FZuAM5pps8BvtBhlmkleSu9w5mnVdWTXefpV1V3VdWLqmqy+Z5ZBxzf/B8dOzOuFJqTUVO30lgFXDvEW2nsrpOAd9L7DfyO5nFK16H2Qb8LXJ3kTuBY4L93G+c5zR7M54DbgbvofS92fiuEJNcAXwdekWRdkvcAy4BfSvIAvT2cZWOY8WPAYcDy5vvlT8cs3z7D21xIklozbk9BkrR9loIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJa/x/4N7Ec0VAcUQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xtrain['HomeForm'].plot.hist()\n",
    "plt.title('HomeForm')\n",
    "plt.show()\n",
    "Xtrain['HomeAtt'].plot.density()\n",
    "plt.title('HomeAtt')\n",
    "plt.show()\n",
    "Xtrain['HomeDef'].plot.density()\n",
    "plt.title('HomeDef')\n",
    "plt.show()\n",
    "Xtrain['HomeMid'].plot.density()\n",
    "plt.title('HomeMid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb66e0",
   "metadata": {},
   "source": [
    "### Pre-Proccessing: We will encode the HomeTeam, AwayTeam and the Ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "326b2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def X_fit_with_dummy(X, feature, na_val):\n",
    "    '''\n",
    "    Encode a categorical feature with dummy variables and return the unique values, encoder object, and the new dataset\n",
    "    Parameters:\n",
    "        X: Input dataset\n",
    "        feature: Name of the categorical feature to be encoded\n",
    "        na_val: Value to replace missing values in the feature\n",
    "    Returns:\n",
    "        values: Unique values of the feature\n",
    "        encoder: Encoder object used for transformation\n",
    "        new_df: DataFrame with encoded dummy variables\n",
    "    '''\n",
    "    X[feature].fillna(na_val, inplace=True)\n",
    "    values = X[feature].unique()\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    dummy_var = encoder.fit_transform(X[[feature]]).toarray()\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    dummy_df = pd.DataFrame(dummy_var, columns=encoder.get_feature_names_out([feature]))\n",
    "    new_df = pd.concat([X, dummy_df], axis=1)\n",
    "    #new_df.drop([feature, feature+'_'+na_val],axis=1, inplace=True) ## We don't need it, no NA\n",
    "    return values, encoder, new_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def X_with_dummy(X, feature, na_val, encoder, train_values):\n",
    "    '''\n",
    "    Encode a categorical feature with dummy variables based on an existing encoder object and return the modified dataset\n",
    "    Parameters:\n",
    "        X: Input dataframe\n",
    "        feature: Name of the categorical feature to be encoded\n",
    "        na_val: Value to replace missing values in the feature\n",
    "        encoder: Encoder object for transforming the feature (CustomEncoder)\n",
    "        train_values: Unique values of the feature in the training data\n",
    "    Returns:\n",
    "        X: DataFrame with encoded dummy variables\n",
    "    '''\n",
    "    X[feature].fillna(na_val, inplace=True)\n",
    "    \n",
    "    # Replace categories not in the known set with 'unknown' in the test data\n",
    "    X[feature] = X[feature].apply(lambda x: x if x in train_values else 'unknown')\n",
    "    \n",
    "    dummy_variables = encoder.transform(X[[feature]]).toarray()\n",
    "    dummy_df = pd.DataFrame(dummy_variables, columns=encoder.get_feature_names_out([feature]))\n",
    "    \n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    X = pd.concat([X, dummy_df], axis=1)\n",
    "    #X.drop([feature, feature+'_'+na_val], axis=1, inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8d30acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Home Team\n",
    "team_val, enc, Xtrain = X_fit_with_dummy(Xtrain, 'HomeTeam', 'unknown')\n",
    "Xtest = X_with_dummy(Xtest, 'HomeTeam', 'unknown', enc, team_val)\n",
    "\n",
    "### Away Team\n",
    "team_val, enc, Xtrain = X_fit_with_dummy(Xtrain, 'AwayTeam', 'unknown')\n",
    "Xtest = X_with_dummy(Xtest, 'AwayTeam', 'unknown', enc, team_val)\n",
    "\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "35c864a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.drop(['HomeTeam', 'AwayTeam', 'Ref'], inplace=True, axis=1)\n",
    "Xtest.drop(['HomeTeam', 'AwayTeam', 'Ref'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf20b76",
   "metadata": {},
   "source": [
    "## Now that we only have numeric values:\n",
    "\n",
    "#### We can now consider further manipulation to the data\n",
    "\n",
    "lets start by doing log(HomeX/AwayX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a94d5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "later_removed = ['HomeAtt', 'HomeMid', 'HomeDef', 'HomeOVR',\n",
    "                 'AwayAtt', 'AwayMid', 'AwayDef', 'AwayOVR']\n",
    "\n",
    "factors = ['Att', 'Def', 'Mid', 'OVR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e72e727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emphasis(df, factors, base):\n",
    "    for f in factors:\n",
    "        df['Home'+f+'to'+base] = np.log(df[\"Home\"+f]) - np.log(df['Home'+base])\n",
    "        df['Away'+f+'to'+base] = np.log(df[\"Away\"+f]) - np.log(df['Away'+base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2d8b384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_emphasis(Xtrain, ['Att', 'Def', 'Mid'], 'OVR')\n",
    "get_emphasis(Xtest, ['Att', 'Def', 'Mid'], 'OVR')\n",
    "\n",
    "Xtrain.drop(later_removed, inplace=True, axis=1)\n",
    "Xtest.drop(later_removed, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "041e797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomeForm                     int64\n",
      "AwayForm                     int64\n",
      "HomeMissingPlayers           int64\n",
      "AwayMissingPlayers           int64\n",
      "Month                        int64\n",
      "Round_Number                 int64\n",
      "HomeTeam_Arsenal           float64\n",
      "HomeTeam_Aston Villa       float64\n",
      "HomeTeam_Bournemouth       float64\n",
      "HomeTeam_Brentford         float64\n",
      "HomeTeam_Brighton          float64\n",
      "HomeTeam_Burnley           float64\n",
      "HomeTeam_Cardiff           float64\n",
      "HomeTeam_Chelsea           float64\n",
      "HomeTeam_Crystal Palace    float64\n",
      "HomeTeam_Everton           float64\n",
      "HomeTeam_Fulham            float64\n",
      "HomeTeam_Huddersfield      float64\n",
      "HomeTeam_Leeds             float64\n",
      "HomeTeam_Leicester         float64\n",
      "HomeTeam_Liverpool         float64\n",
      "HomeTeam_Man City          float64\n",
      "HomeTeam_Man United        float64\n",
      "HomeTeam_Newcastle         float64\n",
      "HomeTeam_Norwich           float64\n",
      "HomeTeam_Nottm Forest      float64\n",
      "HomeTeam_Southampton       float64\n",
      "HomeTeam_Tottenham         float64\n",
      "HomeTeam_Watford           float64\n",
      "HomeTeam_West Ham          float64\n",
      "HomeTeam_Wolves            float64\n",
      "AwayTeam_Arsenal           float64\n",
      "AwayTeam_Aston Villa       float64\n",
      "AwayTeam_Bournemouth       float64\n",
      "AwayTeam_Brentford         float64\n",
      "AwayTeam_Brighton          float64\n",
      "AwayTeam_Burnley           float64\n",
      "AwayTeam_Cardiff           float64\n",
      "AwayTeam_Chelsea           float64\n",
      "AwayTeam_Crystal Palace    float64\n",
      "AwayTeam_Everton           float64\n",
      "AwayTeam_Fulham            float64\n",
      "AwayTeam_Huddersfield      float64\n",
      "AwayTeam_Leeds             float64\n",
      "AwayTeam_Leicester         float64\n",
      "AwayTeam_Liverpool         float64\n",
      "AwayTeam_Man City          float64\n",
      "AwayTeam_Man United        float64\n",
      "AwayTeam_Newcastle         float64\n",
      "AwayTeam_Norwich           float64\n",
      "AwayTeam_Nottm Forest      float64\n",
      "AwayTeam_Southampton       float64\n",
      "AwayTeam_Tottenham         float64\n",
      "AwayTeam_Watford           float64\n",
      "AwayTeam_West Ham          float64\n",
      "AwayTeam_Wolves            float64\n",
      "HomeAtttoOVR               float64\n",
      "AwayAtttoOVR               float64\n",
      "HomeDeftoOVR               float64\n",
      "AwayDeftoOVR               float64\n",
      "HomeMidtoOVR               float64\n",
      "AwayMidtoOVR               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get the column types\n",
    "column_types = Xtrain.dtypes\n",
    "\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f27ef735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeForm</th>\n",
       "      <th>AwayForm</th>\n",
       "      <th>HomeMissingPlayers</th>\n",
       "      <th>AwayMissingPlayers</th>\n",
       "      <th>Month</th>\n",
       "      <th>Round_Number</th>\n",
       "      <th>HomeTeam_Arsenal</th>\n",
       "      <th>HomeTeam_Aston Villa</th>\n",
       "      <th>HomeTeam_Bournemouth</th>\n",
       "      <th>HomeTeam_Brentford</th>\n",
       "      <th>HomeTeam_Brighton</th>\n",
       "      <th>HomeTeam_Burnley</th>\n",
       "      <th>HomeTeam_Cardiff</th>\n",
       "      <th>HomeTeam_Chelsea</th>\n",
       "      <th>HomeTeam_Crystal Palace</th>\n",
       "      <th>HomeTeam_Everton</th>\n",
       "      <th>HomeTeam_Fulham</th>\n",
       "      <th>HomeTeam_Huddersfield</th>\n",
       "      <th>HomeTeam_Leeds</th>\n",
       "      <th>HomeTeam_Leicester</th>\n",
       "      <th>HomeTeam_Liverpool</th>\n",
       "      <th>HomeTeam_Man City</th>\n",
       "      <th>HomeTeam_Man United</th>\n",
       "      <th>HomeTeam_Newcastle</th>\n",
       "      <th>HomeTeam_Norwich</th>\n",
       "      <th>HomeTeam_Nottm Forest</th>\n",
       "      <th>HomeTeam_Southampton</th>\n",
       "      <th>HomeTeam_Tottenham</th>\n",
       "      <th>HomeTeam_Watford</th>\n",
       "      <th>HomeTeam_West Ham</th>\n",
       "      <th>HomeTeam_Wolves</th>\n",
       "      <th>AwayTeam_Arsenal</th>\n",
       "      <th>AwayTeam_Aston Villa</th>\n",
       "      <th>AwayTeam_Bournemouth</th>\n",
       "      <th>AwayTeam_Brentford</th>\n",
       "      <th>AwayTeam_Brighton</th>\n",
       "      <th>AwayTeam_Burnley</th>\n",
       "      <th>AwayTeam_Cardiff</th>\n",
       "      <th>AwayTeam_Chelsea</th>\n",
       "      <th>AwayTeam_Crystal Palace</th>\n",
       "      <th>AwayTeam_Everton</th>\n",
       "      <th>AwayTeam_Fulham</th>\n",
       "      <th>AwayTeam_Huddersfield</th>\n",
       "      <th>AwayTeam_Leeds</th>\n",
       "      <th>AwayTeam_Leicester</th>\n",
       "      <th>AwayTeam_Liverpool</th>\n",
       "      <th>AwayTeam_Man City</th>\n",
       "      <th>AwayTeam_Man United</th>\n",
       "      <th>AwayTeam_Newcastle</th>\n",
       "      <th>AwayTeam_Norwich</th>\n",
       "      <th>AwayTeam_Nottm Forest</th>\n",
       "      <th>AwayTeam_Southampton</th>\n",
       "      <th>AwayTeam_Tottenham</th>\n",
       "      <th>AwayTeam_Watford</th>\n",
       "      <th>AwayTeam_West Ham</th>\n",
       "      <th>AwayTeam_Wolves</th>\n",
       "      <th>HomeAtttoOVR</th>\n",
       "      <th>AwayAtttoOVR</th>\n",
       "      <th>HomeDeftoOVR</th>\n",
       "      <th>AwayDeftoOVR</th>\n",
       "      <th>HomeMidtoOVR</th>\n",
       "      <th>AwayMidtoOVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>-0.013245</td>\n",
       "      <td>0.011696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012270</td>\n",
       "      <td>-0.011976</td>\n",
       "      <td>-0.024693</td>\n",
       "      <td>-0.011976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036814</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>-0.012579</td>\n",
       "      <td>-0.012903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>-0.013245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeForm  AwayForm  HomeMissingPlayers  AwayMissingPlayers  Month  Round_Number  HomeTeam_Arsenal  HomeTeam_Aston Villa  HomeTeam_Bournemouth  HomeTeam_Brentford  HomeTeam_Brighton  HomeTeam_Burnley  HomeTeam_Cardiff  HomeTeam_Chelsea  HomeTeam_Crystal Palace  HomeTeam_Everton  HomeTeam_Fulham  HomeTeam_Huddersfield  HomeTeam_Leeds  HomeTeam_Leicester  HomeTeam_Liverpool  HomeTeam_Man City  HomeTeam_Man United  HomeTeam_Newcastle  HomeTeam_Norwich  HomeTeam_Nottm Forest  HomeTeam_Southampton  HomeTeam_Tottenham  HomeTeam_Watford  HomeTeam_West Ham  HomeTeam_Wolves  AwayTeam_Arsenal  AwayTeam_Aston Villa  AwayTeam_Bournemouth  AwayTeam_Brentford  AwayTeam_Brighton  AwayTeam_Burnley  AwayTeam_Cardiff  AwayTeam_Chelsea  AwayTeam_Crystal Palace  AwayTeam_Everton  AwayTeam_Fulham  AwayTeam_Huddersfield  AwayTeam_Leeds  AwayTeam_Leicester  AwayTeam_Liverpool  AwayTeam_Man City  AwayTeam_Man United  AwayTeam_Newcastle  AwayTeam_Norwich  AwayTeam_Nottm Forest  AwayTeam_Southampton  \\\n",
       "0        10         5                   6                   6      5            37               0.0                   0.0                   0.0                 0.0                0.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                0.0                  0.0                 1.0               0.0                    0.0                   0.0                 0.0               0.0                0.0              0.0               0.0                   0.0                   0.0                 0.0                0.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 1.0                 0.0                0.0                  0.0                 0.0               0.0                    0.0                   0.0   \n",
       "1         9        13                   6                   5      5            32               0.0                   0.0                   0.0                 0.0                1.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                0.0                  0.0                 0.0               0.0                    0.0                   0.0                 0.0               0.0                0.0              0.0               0.0                   0.0                   0.0                 0.0                0.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                1.0                  0.0                 0.0               0.0                    0.0                   0.0   \n",
       "2         9         4                   5                   8      5            32               0.0                   0.0                   0.0                 0.0                0.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                0.0                  1.0                 0.0               0.0                    0.0                   0.0                 0.0               0.0                0.0              0.0               0.0                   0.0                   0.0                 0.0                0.0               0.0               0.0               1.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                0.0                  0.0                 0.0               0.0                    0.0                   0.0   \n",
       "3         6         7                   5                   2      5            38               1.0                   0.0                   0.0                 0.0                0.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                0.0                  0.0                 0.0               0.0                    0.0                   0.0                 0.0               0.0                0.0              0.0               0.0                   0.0                   0.0                 0.0                0.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                0.0                  0.0                 0.0               0.0                    0.0                   0.0   \n",
       "4         7         7                   2                   0      5            38               0.0                   1.0                   0.0                 0.0                0.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                0.0                  0.0                 0.0               0.0                    0.0                   0.0                 0.0               0.0                0.0              0.0               0.0                   0.0                   0.0                 0.0                1.0               0.0               0.0               0.0                      0.0               0.0              0.0                    0.0             0.0                 0.0                 0.0                0.0                  0.0                 0.0               0.0                    0.0                   0.0   \n",
       "\n",
       "   AwayTeam_Tottenham  AwayTeam_Watford  AwayTeam_West Ham  AwayTeam_Wolves  HomeAtttoOVR  AwayAtttoOVR  HomeDeftoOVR  AwayDeftoOVR  HomeMidtoOVR  AwayMidtoOVR  \n",
       "0                 0.0               0.0                0.0              0.0      0.000000      0.000000      0.012739     -0.012739     -0.025975      0.000000  \n",
       "1                 0.0               0.0                0.0              0.0      0.000000      0.000000      0.013072      0.011696     -0.013245      0.011696  \n",
       "2                 0.0               0.0                0.0              0.0     -0.012270     -0.011976     -0.024693     -0.011976      0.000000      0.023530  \n",
       "3                 0.0               0.0                0.0              1.0      0.036814      0.012739     -0.012579     -0.012903      0.000000      0.012739  \n",
       "4                 0.0               0.0                0.0              0.0      0.000000      0.000000      0.012579      0.013072     -0.012739     -0.013245  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "df1e765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_normalize_data(train, scaler, col):\n",
    "    '''\n",
    "    Normalize the train data by fit and transform using StandardScaler.\n",
    "    Parameters:\n",
    "        train: Training data to fit and then normalize.\n",
    "        scaler: The scaler object.\n",
    "        col: the column in data to normalzie its observations.\n",
    "    Returns:\n",
    "        train: Updated normalized training data.\n",
    "        sc: Fitted scaler object.\n",
    "    '''\n",
    "    train[col] = scaler.fit_transform(train[col].values.reshape(-1, 1))\n",
    "    return train, scaler\n",
    "\n",
    "\n",
    "def transform_normalize_data(data, scaler, col):\n",
    "    '''\n",
    "    Normalize the data using fitted StandardScaler.\n",
    "    Parameters:\n",
    "        train: data to normalize.\n",
    "        scaler: Fitted scaler object.\n",
    "        col: the column in data to normalzie its observations.\n",
    "    Returns:\n",
    "        train: Updated normalized data.\n",
    "    '''\n",
    "    data[col] = scaler.transform(data[col].values.reshape(-1, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "17ab910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "for col in Xtrain.columns:\n",
    "    Xtrain, scaler = fit_normalize_data(Xtrain, scaler, col)\n",
    "    Xtest = transform_normalize_data(Xtest, scaler, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0633c7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeForm</th>\n",
       "      <th>AwayForm</th>\n",
       "      <th>HomeMissingPlayers</th>\n",
       "      <th>AwayMissingPlayers</th>\n",
       "      <th>Month</th>\n",
       "      <th>Round_Number</th>\n",
       "      <th>HomeTeam_Arsenal</th>\n",
       "      <th>HomeTeam_Aston Villa</th>\n",
       "      <th>HomeTeam_Bournemouth</th>\n",
       "      <th>HomeTeam_Brentford</th>\n",
       "      <th>HomeTeam_Brighton</th>\n",
       "      <th>HomeTeam_Burnley</th>\n",
       "      <th>HomeTeam_Cardiff</th>\n",
       "      <th>HomeTeam_Chelsea</th>\n",
       "      <th>HomeTeam_Crystal Palace</th>\n",
       "      <th>HomeTeam_Everton</th>\n",
       "      <th>HomeTeam_Fulham</th>\n",
       "      <th>HomeTeam_Huddersfield</th>\n",
       "      <th>HomeTeam_Leeds</th>\n",
       "      <th>HomeTeam_Leicester</th>\n",
       "      <th>HomeTeam_Liverpool</th>\n",
       "      <th>HomeTeam_Man City</th>\n",
       "      <th>HomeTeam_Man United</th>\n",
       "      <th>HomeTeam_Newcastle</th>\n",
       "      <th>HomeTeam_Norwich</th>\n",
       "      <th>HomeTeam_Nottm Forest</th>\n",
       "      <th>HomeTeam_Southampton</th>\n",
       "      <th>HomeTeam_Tottenham</th>\n",
       "      <th>HomeTeam_Watford</th>\n",
       "      <th>HomeTeam_West Ham</th>\n",
       "      <th>HomeTeam_Wolves</th>\n",
       "      <th>AwayTeam_Arsenal</th>\n",
       "      <th>AwayTeam_Aston Villa</th>\n",
       "      <th>AwayTeam_Bournemouth</th>\n",
       "      <th>AwayTeam_Brentford</th>\n",
       "      <th>AwayTeam_Brighton</th>\n",
       "      <th>AwayTeam_Burnley</th>\n",
       "      <th>AwayTeam_Cardiff</th>\n",
       "      <th>AwayTeam_Chelsea</th>\n",
       "      <th>AwayTeam_Crystal Palace</th>\n",
       "      <th>AwayTeam_Everton</th>\n",
       "      <th>AwayTeam_Fulham</th>\n",
       "      <th>AwayTeam_Huddersfield</th>\n",
       "      <th>AwayTeam_Leeds</th>\n",
       "      <th>AwayTeam_Leicester</th>\n",
       "      <th>AwayTeam_Liverpool</th>\n",
       "      <th>AwayTeam_Man City</th>\n",
       "      <th>AwayTeam_Man United</th>\n",
       "      <th>AwayTeam_Newcastle</th>\n",
       "      <th>AwayTeam_Norwich</th>\n",
       "      <th>AwayTeam_Nottm Forest</th>\n",
       "      <th>AwayTeam_Southampton</th>\n",
       "      <th>AwayTeam_Tottenham</th>\n",
       "      <th>AwayTeam_Watford</th>\n",
       "      <th>AwayTeam_West Ham</th>\n",
       "      <th>AwayTeam_Wolves</th>\n",
       "      <th>HomeAtttoOVR</th>\n",
       "      <th>AwayAtttoOVR</th>\n",
       "      <th>HomeDeftoOVR</th>\n",
       "      <th>AwayDeftoOVR</th>\n",
       "      <th>HomeMidtoOVR</th>\n",
       "      <th>AwayMidtoOVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.782259</td>\n",
       "      <td>-0.660330</td>\n",
       "      <td>0.857149</td>\n",
       "      <td>0.859670</td>\n",
       "      <td>-0.382557</td>\n",
       "      <td>1.595863</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.473720</td>\n",
       "      <td>-0.473720</td>\n",
       "      <td>1.728511</td>\n",
       "      <td>-0.183807</td>\n",
       "      <td>-1.823513</td>\n",
       "      <td>-0.138734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.504188</td>\n",
       "      <td>1.557796</td>\n",
       "      <td>0.857149</td>\n",
       "      <td>0.390983</td>\n",
       "      <td>-0.382557</td>\n",
       "      <td>1.139902</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.473720</td>\n",
       "      <td>-0.473720</td>\n",
       "      <td>1.753510</td>\n",
       "      <td>1.650228</td>\n",
       "      <td>-0.997824</td>\n",
       "      <td>0.619876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.504188</td>\n",
       "      <td>-0.937596</td>\n",
       "      <td>0.391618</td>\n",
       "      <td>1.797044</td>\n",
       "      <td>-0.382557</td>\n",
       "      <td>1.139902</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-1.134526</td>\n",
       "      <td>-1.118698</td>\n",
       "      <td>-1.081013</td>\n",
       "      <td>-0.126551</td>\n",
       "      <td>-0.138734</td>\n",
       "      <td>1.387463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.330027</td>\n",
       "      <td>-0.105799</td>\n",
       "      <td>0.391618</td>\n",
       "      <td>-1.015077</td>\n",
       "      <td>-0.382557</td>\n",
       "      <td>1.687055</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>1.508898</td>\n",
       "      <td>0.212341</td>\n",
       "      <td>-0.171780</td>\n",
       "      <td>-0.196145</td>\n",
       "      <td>-0.138734</td>\n",
       "      <td>0.687524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.051955</td>\n",
       "      <td>-0.105799</td>\n",
       "      <td>-1.004976</td>\n",
       "      <td>-1.952451</td>\n",
       "      <td>-0.382557</td>\n",
       "      <td>1.687055</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>5.385165</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.130189</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>-0.473720</td>\n",
       "      <td>-0.473720</td>\n",
       "      <td>1.716484</td>\n",
       "      <td>1.753510</td>\n",
       "      <td>-0.964991</td>\n",
       "      <td>-0.997824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeForm  AwayForm  HomeMissingPlayers  AwayMissingPlayers     Month  Round_Number  HomeTeam_Arsenal  HomeTeam_Aston Villa  HomeTeam_Bournemouth  HomeTeam_Brentford  HomeTeam_Brighton  HomeTeam_Burnley  HomeTeam_Cardiff  HomeTeam_Chelsea  HomeTeam_Crystal Palace  HomeTeam_Everton  HomeTeam_Fulham  HomeTeam_Huddersfield  HomeTeam_Leeds  HomeTeam_Leicester  HomeTeam_Liverpool  HomeTeam_Man City  HomeTeam_Man United  HomeTeam_Newcastle  HomeTeam_Norwich  HomeTeam_Nottm Forest  HomeTeam_Southampton  HomeTeam_Tottenham  HomeTeam_Watford  HomeTeam_West Ham  HomeTeam_Wolves  AwayTeam_Arsenal  AwayTeam_Aston Villa  AwayTeam_Bournemouth  AwayTeam_Brentford  AwayTeam_Brighton  AwayTeam_Burnley  AwayTeam_Cardiff  AwayTeam_Chelsea  AwayTeam_Crystal Palace  AwayTeam_Everton  AwayTeam_Fulham  AwayTeam_Huddersfield  AwayTeam_Leeds  AwayTeam_Leicester  AwayTeam_Liverpool  AwayTeam_Man City  AwayTeam_Man United  AwayTeam_Newcastle  AwayTeam_Norwich  AwayTeam_Nottm Forest  AwayTeam_Southampton  \\\n",
       "0  0.782259 -0.660330            0.857149            0.859670 -0.382557      1.595863         -0.229416             -0.185695             -0.185695           -0.185695          -0.229416         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416          -0.229416            -0.229416            4.358899         -0.130189              -0.130189             -0.229416           -0.229416         -0.185695          -0.229416        -0.229416         -0.229416             -0.185695             -0.185695           -0.185695          -0.229416         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695            4.358899           -0.229416          -0.229416            -0.229416           -0.229416         -0.130189              -0.130189             -0.229416   \n",
       "1  0.504188  1.557796            0.857149            0.390983 -0.382557      1.139902         -0.229416             -0.185695             -0.185695           -0.185695           4.358899         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416          -0.229416            -0.229416           -0.229416         -0.130189              -0.130189             -0.229416           -0.229416         -0.185695          -0.229416        -0.229416         -0.229416             -0.185695             -0.185695           -0.185695          -0.229416         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416           4.358899            -0.229416           -0.229416         -0.130189              -0.130189             -0.229416   \n",
       "2  0.504188 -0.937596            0.391618            1.797044 -0.382557      1.139902         -0.229416             -0.185695             -0.185695           -0.185695          -0.229416         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416          -0.229416             4.358899           -0.229416         -0.130189              -0.130189             -0.229416           -0.229416         -0.185695          -0.229416        -0.229416         -0.229416             -0.185695             -0.185695           -0.185695          -0.229416         -0.185695         -0.130189          4.358899                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416          -0.229416            -0.229416           -0.229416         -0.130189              -0.130189             -0.229416   \n",
       "3 -0.330027 -0.105799            0.391618           -1.015077 -0.382557      1.687055          4.358899             -0.185695             -0.185695           -0.185695          -0.229416         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416          -0.229416            -0.229416           -0.229416         -0.130189              -0.130189             -0.229416           -0.229416         -0.185695          -0.229416        -0.229416         -0.229416             -0.185695             -0.185695           -0.185695          -0.229416         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416          -0.229416            -0.229416           -0.229416         -0.130189              -0.130189             -0.229416   \n",
       "4 -0.051955 -0.105799           -1.004976           -1.952451 -0.382557      1.687055         -0.229416              5.385165             -0.185695           -0.185695          -0.229416         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416          -0.229416            -0.229416           -0.229416         -0.130189              -0.130189             -0.229416           -0.229416         -0.185695          -0.229416        -0.229416         -0.229416             -0.185695             -0.185695           -0.185695           4.358899         -0.185695         -0.130189         -0.229416                -0.229416         -0.229416        -0.185695              -0.130189       -0.185695           -0.229416           -0.229416          -0.229416            -0.229416           -0.229416         -0.130189              -0.130189             -0.229416   \n",
       "\n",
       "   AwayTeam_Tottenham  AwayTeam_Watford  AwayTeam_West Ham  AwayTeam_Wolves  HomeAtttoOVR  AwayAtttoOVR  HomeDeftoOVR  AwayDeftoOVR  HomeMidtoOVR  AwayMidtoOVR  \n",
       "0           -0.229416         -0.185695          -0.229416        -0.229416     -0.473720     -0.473720      1.728511     -0.183807     -1.823513     -0.138734  \n",
       "1           -0.229416         -0.185695          -0.229416        -0.229416     -0.473720     -0.473720      1.753510      1.650228     -0.997824      0.619876  \n",
       "2           -0.229416         -0.185695          -0.229416        -0.229416     -1.134526     -1.118698     -1.081013     -0.126551     -0.138734      1.387463  \n",
       "3           -0.229416         -0.185695          -0.229416         4.358899      1.508898      0.212341     -0.171780     -0.196145     -0.138734      0.687524  \n",
       "4           -0.229416         -0.185695          -0.229416        -0.229416     -0.473720     -0.473720      1.716484      1.753510     -0.964991     -0.997824  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4e5c37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a functino that will perform a grid search on model\n",
    "\n",
    "def getBestModel(estimator, params, XTrain, ytrain, v=3, nj=1):\n",
    "    '''\n",
    "    Performs grid search cross-validation to find the best model based on the given estimator and parameter grid.\n",
    "    Trains the best model on the training data and evaluates its performance on the test data.\n",
    "    Parameters:\n",
    "        estimator: object, the model estimator.\n",
    "        params: dict, the parameter grid for grid search.\n",
    "        XTrain: DataFrame, the training features.\n",
    "        ytrain: Series, the training labels.\n",
    "        XTest: DataFrame, the test features.\n",
    "        ytest: Series, the test labels.\n",
    "        v: int, verbose level for grid search (default=3).\n",
    "        nj: int, number of parallel jobs for grid search (default=1).\n",
    "    Returns:\n",
    "        best_estimator: object, the best model based on cross-validation.\n",
    "    '''\n",
    "    cv = GridSearchCV(estimator= estimator, param_grid=params, verbose=v, scoring='roc_auc_ovo', cv=3, n_jobs=nj)\n",
    "    cv.fit(XTrain, ytrain)\n",
    "    print(\"Best Parameters:\",  cv.best_params_)\n",
    "    print(\"With the CV score of\",cv.best_score_)\n",
    "    return cv.best_estimator_\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6e1b21dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 88 candidates, totalling 264 fits\n",
      "[CV 1/3] END C=1e-10, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-10, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-10, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-10, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-10, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-10, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-10, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-10, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-10, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-10, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-10, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-10, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-10, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-10, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-10, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-10, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-10, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-10, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-10, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-10, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-10, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-10, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-10, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-10, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-09, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-09, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-09, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-09, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-09, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-09, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-09, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-09, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-09, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-09, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-09, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-09, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-09, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-09, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-09, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-09, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-09, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-09, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-09, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-09, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-09, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-09, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-09, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-09, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-08, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-08, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-08, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-08, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-08, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-08, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-08, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-08, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-08, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-08, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-08, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-08, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-08, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-08, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-08, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-08, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-08, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-08, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-08, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-08, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-08, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-08, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-08, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-08, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-07, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-07, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-07, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-07, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-07, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-07, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-07, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-07, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-07, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-07, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-07, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-07, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-07, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-07, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-07, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-07, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-07, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-07, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-07, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-07, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-07, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-07, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-07, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-07, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-06, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-06, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-06, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-06, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-06, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-06, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-06, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-06, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-06, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-06, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-06, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-06, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-06, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-06, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-06, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-06, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-06, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-06, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-06, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-06, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-06, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-06, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-06, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-06, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-05, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-05, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-05, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-05, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-05, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-05, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-05, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-05, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-05, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-05, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=1e-05, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=1e-05, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=1e-05, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-05, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-05, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-05, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-05, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-05, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=1e-05, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=1e-05, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=1e-05, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=1e-05, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=1e-05, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=1e-05, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=0.0001, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.0001, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.0001, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.0001, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=0.0001, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=0.0001, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=0.0001, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.0001, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.0001, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.0001, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=0.0001, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.648 total time=   0.0s\n",
      "[CV 3/3] END C=0.0001, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END C=0.0001, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.0001, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.0001, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.0001, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=0.0001, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=0.0001, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=0.0001, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.0001, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.0001, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.0001, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 2/3] END C=0.0001, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.649 total time=   0.0s\n",
      "[CV 3/3] END C=0.0001, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.619 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.646 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.620 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.646 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.623 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.625 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.646 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.616 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.646 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.614 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.611 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.642 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.618 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.613 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.638 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.607 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.616 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.641 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.609 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.614 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.636 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.596 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.612 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.639 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.637 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.594 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.602 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.616 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.636 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.586 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.588 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.599 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.613 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.638 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.636 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.598 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.631 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.596 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.613 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.636 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.637 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.586 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.628 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.586 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.592 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.603 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.581 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.593 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.588 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.633 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.606 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.577 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.627 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.599 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.595 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, fit_intercept=True, penalty=l1, solver=liblinear;, score=0.602 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.582 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, fit_intercept=True, penalty=l2, solver=liblinear;, score=0.587 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.590 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, fit_intercept=False, penalty=l1, solver=liblinear;, score=0.587 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.579 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.626 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, fit_intercept=False, penalty=l2, solver=liblinear;, score=0.587 total time=   0.0s\n",
      "Best Parameters: {'C': 0.0001, 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "With the CV score of 0.6316110550729204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "powers = range(-10,1)\n",
    "Cs = [10**p for p in powers] #This is the inverse value for the lambda parameter.\n",
    "\n",
    "lr = LogisticRegression()\n",
    "params = {'C' : Cs,\n",
    "          'solver' : ['liblinear'],\n",
    "         'fit_intercept' : [True, False], \n",
    "         'penalty' : ['l1', 'l2'],\n",
    "         'class_weight':['balanced', None]}\n",
    "lr_best_model = getBestModel(lr, params, Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e832374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_clf = ensemble.RandomForestClassifier(random_state=0, n_estimators=1000)\n",
    "gbm_clf = ensemble.GradientBoostingClassifier(random_state=0)\n",
    "ada_clf = ensemble.AdaBoostClassifier(random_state=0)\n",
    "\n",
    "ada_params = {'n_estimators' : [50, 100, 200, 500, 1000],\n",
    "              'learning_rate' : [0.15, 0.5, 1],}\n",
    "gbm_params = {'learning_rate' : [0.1],\n",
    "              'max_depth' : [1, 2, 3, 4, 5],\n",
    "              'max_features' : ['sqrt'], \n",
    "              'n_estimators' : [500]} #### We will edit this later to have more hyperparameters\n",
    "\n",
    "#Best Parameters: {'learning_rate': 0.1, 'max_depth': 10, 'max_features': 0.3, 'n_estimators': 1000}\n",
    "#With the CV score of 0.9809060813091156\n",
    "\n",
    "#\n",
    "r_params = {'max_features' : ['sqrt', 0.2, 0.3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "473d3e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV 1/3] END .................max_features=sqrt;, score=0.594 total time=   2.9s\n",
      "[CV 2/3] END .................max_features=sqrt;, score=0.609 total time=   2.8s\n",
      "[CV 3/3] END .................max_features=sqrt;, score=0.616 total time=   2.9s\n",
      "[CV 1/3] END ..................max_features=0.2;, score=0.584 total time=   3.0s\n",
      "[CV 2/3] END ..................max_features=0.2;, score=0.585 total time=   3.1s\n",
      "[CV 3/3] END ..................max_features=0.2;, score=0.616 total time=   3.3s\n",
      "[CV 1/3] END ..................max_features=0.3;, score=0.585 total time=   3.6s\n",
      "[CV 2/3] END ..................max_features=0.3;, score=0.578 total time=   4.1s\n",
      "[CV 3/3] END ..................max_features=0.3;, score=0.610 total time=   3.6s\n",
      "Best Parameters: {'max_features': 'sqrt'}\n",
      "With the CV score of 0.6066584098683757\n"
     ]
    }
   ],
   "source": [
    "best_r = getBestModel(r_clf, r_params, Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3ec35491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=1, max_features=sqrt, n_estimators=500;, score=0.581 total time=   1.2s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=1, max_features=sqrt, n_estimators=500;, score=0.644 total time=   1.2s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=1, max_features=sqrt, n_estimators=500;, score=0.636 total time=   1.2s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, max_features=sqrt, n_estimators=500;, score=0.562 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, max_features=sqrt, n_estimators=500;, score=0.634 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, max_features=sqrt, n_estimators=500;, score=0.636 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, n_estimators=500;, score=0.560 total time=   1.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, n_estimators=500;, score=0.628 total time=   1.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, n_estimators=500;, score=0.627 total time=   1.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.562 total time=   2.1s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.624 total time=   2.1s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, max_features=sqrt, n_estimators=500;, score=0.617 total time=   2.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.558 total time=   2.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.620 total time=   2.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, n_estimators=500;, score=0.611 total time=   2.5s\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "With the CV score of 0.6204103585838392\n"
     ]
    }
   ],
   "source": [
    "best_gbm = getBestModel(gbm_clf, gbm_params, Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f13a0113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 99 candidates, totalling 297 fits\n",
      "[CV 1/3] END .....................n_neighbors=1;, score=0.546 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=1;, score=0.580 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=1;, score=0.556 total time=   0.0s\n",
      "[CV 1/3] END .....................n_neighbors=2;, score=0.568 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=2;, score=0.578 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=2;, score=0.579 total time=   0.0s\n",
      "[CV 1/3] END .....................n_neighbors=3;, score=0.564 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=3;, score=0.587 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=3;, score=0.594 total time=   0.0s\n",
      "[CV 1/3] END .....................n_neighbors=4;, score=0.563 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=4;, score=0.620 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=4;, score=0.594 total time=   0.0s\n",
      "[CV 1/3] END .....................n_neighbors=5;, score=0.567 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=5;, score=0.618 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=5;, score=0.587 total time=   0.0s\n",
      "[CV 1/3] END .....................n_neighbors=6;, score=0.564 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=6;, score=0.623 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=6;, score=0.574 total time=   0.0s\n",
      "[CV 1/3] END .....................n_neighbors=7;, score=0.580 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=7;, score=0.620 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=7;, score=0.572 total time=   0.0s\n",
      "[CV 1/3] END .....................n_neighbors=8;, score=0.577 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=8;, score=0.608 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=8;, score=0.569 total time=   0.0s\n",
      "[CV 1/3] END .....................n_neighbors=9;, score=0.570 total time=   0.0s\n",
      "[CV 2/3] END .....................n_neighbors=9;, score=0.617 total time=   0.0s\n",
      "[CV 3/3] END .....................n_neighbors=9;, score=0.572 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=10;, score=0.561 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=10;, score=0.616 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=10;, score=0.581 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=11;, score=0.556 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=11;, score=0.610 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=11;, score=0.583 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=12;, score=0.553 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=12;, score=0.605 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=12;, score=0.582 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=13;, score=0.559 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=13;, score=0.611 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=13;, score=0.586 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=14;, score=0.564 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=14;, score=0.608 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=14;, score=0.598 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=15;, score=0.561 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=15;, score=0.609 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=15;, score=0.596 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=16;, score=0.568 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=16;, score=0.612 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=16;, score=0.601 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=17;, score=0.572 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=17;, score=0.612 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=17;, score=0.605 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=18;, score=0.571 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=18;, score=0.613 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=18;, score=0.601 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=19;, score=0.574 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=19;, score=0.615 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=19;, score=0.605 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=20;, score=0.574 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=20;, score=0.613 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=20;, score=0.600 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=21;, score=0.573 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=21;, score=0.603 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=21;, score=0.598 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=22;, score=0.578 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=22;, score=0.601 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=22;, score=0.598 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=23;, score=0.576 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=23;, score=0.602 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=23;, score=0.599 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=24;, score=0.580 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=24;, score=0.604 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=24;, score=0.593 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=25;, score=0.580 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=25;, score=0.608 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=25;, score=0.597 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=26;, score=0.580 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=26;, score=0.607 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=26;, score=0.598 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=27;, score=0.583 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=27;, score=0.609 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=27;, score=0.606 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=28;, score=0.587 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=28;, score=0.617 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=28;, score=0.610 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=29;, score=0.584 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=29;, score=0.618 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=29;, score=0.612 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=30;, score=0.585 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=30;, score=0.614 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=30;, score=0.614 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=31;, score=0.587 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=31;, score=0.620 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=31;, score=0.616 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=32;, score=0.587 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=32;, score=0.619 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=32;, score=0.618 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=33;, score=0.585 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=33;, score=0.627 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=33;, score=0.618 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=34;, score=0.588 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=34;, score=0.621 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=34;, score=0.623 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=35;, score=0.588 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=35;, score=0.625 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=35;, score=0.623 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=36;, score=0.588 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=36;, score=0.626 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=36;, score=0.624 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=37;, score=0.587 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=37;, score=0.625 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=37;, score=0.623 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=38;, score=0.587 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=38;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=38;, score=0.628 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=39;, score=0.593 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=39;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=39;, score=0.629 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=40;, score=0.593 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=40;, score=0.636 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=40;, score=0.632 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=41;, score=0.600 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=41;, score=0.638 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=41;, score=0.630 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=42;, score=0.604 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=42;, score=0.634 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=42;, score=0.632 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=43;, score=0.604 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=43;, score=0.634 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=43;, score=0.632 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=44;, score=0.600 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=44;, score=0.635 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=44;, score=0.633 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=45;, score=0.601 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=45;, score=0.631 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=45;, score=0.634 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=46;, score=0.606 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=46;, score=0.633 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=46;, score=0.631 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=47;, score=0.607 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=47;, score=0.640 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=47;, score=0.627 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=48;, score=0.607 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=48;, score=0.640 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=48;, score=0.624 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=49;, score=0.607 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=49;, score=0.642 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=49;, score=0.622 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=50;, score=0.610 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=50;, score=0.643 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=50;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=51;, score=0.606 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=51;, score=0.643 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=51;, score=0.622 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=52;, score=0.607 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=52;, score=0.644 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=52;, score=0.622 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=53;, score=0.609 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=53;, score=0.645 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=53;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=54;, score=0.609 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=54;, score=0.644 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=54;, score=0.627 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=55;, score=0.611 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=55;, score=0.647 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=55;, score=0.627 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=56;, score=0.613 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=56;, score=0.642 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=56;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=57;, score=0.614 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=57;, score=0.642 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=57;, score=0.623 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=58;, score=0.614 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=58;, score=0.643 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=58;, score=0.624 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=59;, score=0.615 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=59;, score=0.645 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=59;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=60;, score=0.615 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=60;, score=0.644 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=60;, score=0.627 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=61;, score=0.614 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=61;, score=0.644 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=61;, score=0.628 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=62;, score=0.608 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=62;, score=0.647 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=62;, score=0.628 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=63;, score=0.609 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=63;, score=0.643 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=63;, score=0.627 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=64;, score=0.613 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=64;, score=0.641 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=64;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=65;, score=0.612 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=65;, score=0.643 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=65;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=66;, score=0.609 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=66;, score=0.644 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=66;, score=0.624 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=67;, score=0.609 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=67;, score=0.644 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=67;, score=0.628 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=68;, score=0.612 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=68;, score=0.644 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=68;, score=0.626 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=69;, score=0.609 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=69;, score=0.640 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=69;, score=0.627 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=70;, score=0.608 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=70;, score=0.640 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=70;, score=0.624 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=71;, score=0.610 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=71;, score=0.636 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=71;, score=0.624 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=72;, score=0.610 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=72;, score=0.635 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=72;, score=0.625 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=73;, score=0.612 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=73;, score=0.635 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=73;, score=0.621 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=74;, score=0.607 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=74;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=74;, score=0.621 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=75;, score=0.609 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=75;, score=0.633 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=75;, score=0.619 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=76;, score=0.611 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=76;, score=0.637 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=76;, score=0.621 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=77;, score=0.606 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=77;, score=0.635 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=77;, score=0.618 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=78;, score=0.604 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=78;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=78;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=79;, score=0.607 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=79;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=79;, score=0.616 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=80;, score=0.608 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=80;, score=0.631 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=80;, score=0.618 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=81;, score=0.603 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=81;, score=0.629 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=81;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=82;, score=0.603 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=82;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=82;, score=0.616 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=83;, score=0.605 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=83;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=83;, score=0.617 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=84;, score=0.603 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=84;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=84;, score=0.616 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=85;, score=0.602 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=85;, score=0.634 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=85;, score=0.616 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=86;, score=0.600 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=86;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=86;, score=0.615 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=87;, score=0.601 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=87;, score=0.633 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=87;, score=0.618 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=88;, score=0.603 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=88;, score=0.631 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=88;, score=0.616 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=89;, score=0.602 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=89;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=89;, score=0.614 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=90;, score=0.603 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=90;, score=0.633 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=90;, score=0.614 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=91;, score=0.603 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=91;, score=0.631 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=91;, score=0.611 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=92;, score=0.603 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=92;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=92;, score=0.612 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=93;, score=0.602 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=93;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=93;, score=0.614 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=94;, score=0.606 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=94;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=94;, score=0.610 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=95;, score=0.608 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=95;, score=0.632 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=95;, score=0.613 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=96;, score=0.610 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=96;, score=0.636 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=96;, score=0.614 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=97;, score=0.612 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=97;, score=0.638 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=97;, score=0.615 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=98;, score=0.611 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=98;, score=0.638 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=98;, score=0.613 total time=   0.0s\n",
      "[CV 1/3] END ....................n_neighbors=99;, score=0.611 total time=   0.0s\n",
      "[CV 2/3] END ....................n_neighbors=99;, score=0.638 total time=   0.0s\n",
      "[CV 3/3] END ....................n_neighbors=99;, score=0.616 total time=   0.0s\n",
      "Best Parameters: {'n_neighbors': 60}\n",
      "With the CV score of 0.6289204015363552\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "kparams = {'n_neighbors': range(1, 100)}\n",
    "knn_cv = getBestModel(knn, kparams, Xtrain, y_train, nj = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "86adb15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=0.1;, score=0.578 total time=   0.2s\n",
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=0.1;, score=0.632 total time=   0.2s\n",
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=0.1;, score=0.569 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=0.5;, score=0.570 total time=   0.3s\n",
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=0.5;, score=0.609 total time=   0.3s\n",
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=0.5;, score=0.567 total time=   0.2s\n",
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=1;, score=0.563 total time=   0.1s\n",
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=1;, score=0.611 total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=1, learning_rate_init=1;, score=0.580 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=0.1;, score=0.558 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=0.1;, score=0.606 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=0.1;, score=0.580 total time=   0.3s\n",
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=0.5;, score=0.567 total time=   0.2s\n",
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=0.5;, score=0.603 total time=   0.2s\n",
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=0.5;, score=0.557 total time=   0.2s\n",
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=1;, score=0.567 total time=   0.2s\n",
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=1;, score=0.620 total time=   0.1s\n",
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=20, learning_rate_init=1;, score=0.574 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=0.1;, score=0.564 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=0.1;, score=0.616 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=0.1;, score=0.598 total time=   0.8s\n",
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=0.5;, score=0.569 total time=   0.4s\n",
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=0.5;, score=0.578 total time=   0.4s\n",
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=0.5;, score=0.596 total time=   0.4s\n",
      "[CV 1/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=1;, score=0.539 total time=   0.4s\n",
      "[CV 2/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=1;, score=0.571 total time=   0.5s\n",
      "[CV 3/3] END alpha=0.001, hidden_layer_sizes=100, learning_rate_init=1;, score=0.603 total time=   0.5s\n",
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=0.1;, score=0.578 total time=   0.2s\n",
      "[CV 2/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=0.1;, score=0.632 total time=   0.1s\n",
      "[CV 3/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=0.1;, score=0.582 total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=0.5;, score=0.558 total time=   0.2s\n",
      "[CV 2/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=0.5;, score=0.630 total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=0.5;, score=0.591 total time=   0.3s\n",
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=1;, score=0.569 total time=   0.1s\n",
      "[CV 2/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=1;, score=0.614 total time=   0.1s\n",
      "[CV 3/3] END alpha=0.01, hidden_layer_sizes=1, learning_rate_init=1;, score=0.587 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=20, learning_rate_init=0.1;, score=0.571 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END alpha=0.01, hidden_layer_sizes=20, learning_rate_init=0.1;, score=0.611 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END alpha=0.01, hidden_layer_sizes=20, learning_rate_init=0.1;, score=0.581 total time=   0.3s\n",
      "[CV 1/3] END alpha=0.01, hidden_layer_sizes=20, learning_rate_init=0.5;, score=0.561 total time=   0.2s\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(solver='sgd', activation='logistic')\n",
    "mlp_params = {'alpha' : [0.001, 0.01, .1, 1],\n",
    "          'learning_rate_init' : [0.1, 0.5, 1],\n",
    "          'hidden_layer_sizes' : [1000]}\n",
    "\n",
    "mlp_cv = getBestModel(mlp_clf, mlp_params, Xtrain, y_train, nj = None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
