{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e9cf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a240261",
   "metadata": {},
   "source": [
    "We will start with scraping one match:\n",
    "\n",
    "We want to get the following:\n",
    "\n",
    "1. Team Names (Home - Away)\n",
    "2. Goals\n",
    "3. Amount of missing players per team\n",
    "4. Month\n",
    "5. GD Per team prior to the match (or something else that shows the form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1818ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(form):\n",
    "    # Initialize the sum\n",
    "    total_sum = 0\n",
    "\n",
    "    # Define color-to-value mapping\n",
    "    color_values = {\n",
    "        \"var(--TeamForm-green)\": 3,\n",
    "        \"var(--TeamForm-grey)\": 1,\n",
    "        \"var(--TeamForm-red)\": 0\n",
    "    }\n",
    "\n",
    "\n",
    "    # Iterate through the match items\n",
    "    match_items = form.find_all('li', class_='css-tgulmi-TeamFormContainerRow e3w5gu44')\n",
    "\n",
    "    for match_item in match_items:\n",
    "        result_div = match_item.find('div', color=[\"var(--TeamForm-green)\", \"var(--TeamForm-grey)\", \"var(--TeamForm-red)\"])\n",
    "        \n",
    "        # Exclude the horizontal line element\n",
    "        if result_div and not result_div.find_previous_sibling('div', class_='css-xw5oij-HorizontalLine ecz4wo11'):\n",
    "            color = result_div.get('color')\n",
    "            \n",
    "            if color:\n",
    "                value = color_values.get(color)\n",
    "                \n",
    "                if value is not None:\n",
    "                    total_sum += value\n",
    "    return total_sum\n",
    "\n",
    "def scrape_match(url, i):\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(url)\n",
    "    # Extract home team name, away team name, and score\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    home_team_name = soup.find('span', class_='css-q98y93-TeamNameItself-TeamNameOnMobile-hideOnTabletOrBigger').text.strip()\n",
    "    away_team_name = soup.find_all('span', class_='css-q98y93-TeamNameItself-TeamNameOnMobile-hideOnTabletOrBigger')[1].text.strip()\n",
    "    score = soup.find('span', class_='css-ta04x1-MFHeaderStatusScore-topRow').text.strip()\n",
    "    scores = score.split()\n",
    "    home_score = int(scores[0])\n",
    "    away_score = int(scores[-1])\n",
    "    scores_string = home_score, away_score\n",
    "\n",
    "\n",
    "    # Close the WebDriver\n",
    "    \n",
    "\n",
    "    # Count the number of <a> elements\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "    injured_and_missing = soup.find_all('div', class_='css-1ou3v7p-LineupAdditionalContainer ejc6in01')[-1]\n",
    "    injured_lists = injured_and_missing.find_all('div', class_='css-1xyusi4-LineupAdditionalSideContainer ejc6in00')\n",
    "    home_injured = injured_lists[0]\n",
    "    # Assuming you already have the 'home_injured' element\n",
    "    a_elements = home_injured.find_all('a', href=True)\n",
    "    # Count the number of <a> elements within 'home_injured'\n",
    "    count = len(a_elements)\n",
    "\n",
    "    # doing the one for the away team\n",
    "    away_injured = injured_lists[1]\n",
    "    home_missing = count\n",
    "    # Print the count\n",
    "    print(f\"Number of <a href> elements within 'home_injured': {count}\")\n",
    "\n",
    "    a_elements = away_injured.find_all('a', href=True)\n",
    "    # Count the number of <a> elements within 'home_injured'\n",
    "    count = len(a_elements)\n",
    "    print(f\"Number of <a href> elements within 'away_injured': {count}\")\n",
    "    away_missing = count\n",
    "\n",
    "    #### and doing one for the team form:\n",
    "    wrap = soup.find('div', class_='css-qas03g-RightColumn-commonColumn eozzfav0')\n",
    "    form = wrap.find('div', class_='css-1p6t12o-TeamFormColumnsWrapper eqza12c0')\n",
    "    home_form = form.find('ul', class_='css-1mgoca0-TeamFormContainerList e3w5gu45')\n",
    "    away_form = form.find('ul', class_='css-1g2soyd-TeamFormContainerList e3w5gu45')\n",
    "    \n",
    "    home_sum = get_points(home_form)\n",
    "    away_sum = get_points(away_form)\n",
    "    match_time_element = soup.find_all('time', datetime=True)[-1]\n",
    "    if match_time_element:\n",
    "        match_time = match_time_element.text.strip()\n",
    "    else:\n",
    "        match_time = \"N/A\"\n",
    "\n",
    "    # Find the <span> element with the specified class\n",
    "    referee_element = soup.find_all('span', class_='css-1scisqg-InfoBoxValue ejh09150')[3]\n",
    "    if referee_element:\n",
    "        referee_name = referee_element.text.strip()\n",
    "    else:\n",
    "        referee_name = \"N/A\"\n",
    "    # Find the match rounds element\n",
    "    match_round_element = soup.find('div', class_='css-1m0k67e-MiddleGridItem erezbcv3')\n",
    "    match_round_text = match_round_element.find('span').text.strip() if match_round_element else \"N/A\"\n",
    "    match_round = match_round_text if match_round_text else \"N/A\"\n",
    "\n",
    "\n",
    "    ### Getting the Head To Head Stats\n",
    "    h_2_h = soup.find('div', {'name':'head to head'})\n",
    "        # Extract the relevant information\n",
    "    wins_element = h_2_h.find('span', class_='css-q6dc64-NumberOfWins ew2zkhp10')\n",
    "    draws_element = h_2_h.find('span', class_='css-10nshmy-NumberOfWins')\n",
    "    losses_element = h_2_h.find('span', class_='css-x6i3js-NumberOfWins ew2zkhp10')\n",
    "\n",
    "    # Get the text content of each element\n",
    "    wins = int(wins_element.get_text()) if wins_element else 0\n",
    "    draws = int(draws_element.get_text()) if draws_element else 0\n",
    "    losses = int(losses_element.get_text()) if losses_element else 0\n",
    "\n",
    "\n",
    "        \n",
    "    # Print the results\n",
    "    print(f\"Wins: {wins}\")\n",
    "    print(f\"Draws: {draws}\")\n",
    "    print(f\"Losses: {losses}\")\n",
    "    ###\n",
    "    # Print the results\n",
    "    print(f\"Match Round: {match_round}\")\n",
    "    # Print the results\n",
    "    print(f\"Match Time: {match_time}\")\n",
    "    print(f\"Referee: {referee_name}\")\n",
    "    print(f\"Total Sum for the home team: {home_sum}\")\n",
    "    print(f\"Total Sum for the home team: {away_sum}\")\n",
    "    # Print the results\n",
    "    print(f\"Home Team: {home_team_name}\")\n",
    "    print(f\"Away Team: {away_team_name}\")\n",
    "\n",
    "\n",
    "\n",
    "    return pd.DataFrame(data={'HomeTeam' : home_team_name,\n",
    "                         \"AwayTeam\" : away_team_name,\n",
    "                         'HomeScore' : home_score,\n",
    "                         'AwayScore' : away_score,\n",
    "                         'Time' : match_time,\n",
    "                         'Ref' : referee_name,\n",
    "                         'HomeForm' : home_sum,\n",
    "                         'AwayForm' : away_sum,\n",
    "                         'HomeMissingPlayers' : home_missing,\n",
    "                         'AwayMissingPlayers' : away_missing,\n",
    "                         'Round' : match_round}, index=[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of <a href> elements within 'home_injured': 4\n",
      "Number of <a href> elements within 'away_injured': 7\n",
      "Wins: 6\n",
      "Draws: 3\n",
      "Losses: 5\n",
      "Match Round: Premier League Round 36 2022/2023\n",
      "Match Time: May 14, 2023, 6:30 PM\n",
      "Referee: Andy Madley\n",
      "Total Sum for the home team: 8\n",
      "Total Sum for the home team: 6\n",
      "Home Team: Arsenal\n",
      "Away Team: Brighton\n"
     ]
    }
   ],
   "source": [
    "match = scrape_match('https://www.fotmob.com/match/3901282/matchfacts/arsenal-vs-brighton-hove-albion', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96db0361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeScore</th>\n",
       "      <th>AwayScore</th>\n",
       "      <th>Time</th>\n",
       "      <th>Ref</th>\n",
       "      <th>HomeForm</th>\n",
       "      <th>AwayForm</th>\n",
       "      <th>HomeMissingPlayers</th>\n",
       "      <th>AwayMissingPlayers</th>\n",
       "      <th>Round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>May 14, 2023, 6:30 PM</td>\n",
       "      <td>Andy Madley</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Premier League Round 36 2022/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomeTeam  AwayTeam  HomeScore  AwayScore                   Time          Ref  HomeForm  AwayForm  HomeMissingPlayers  AwayMissingPlayers                              Round\n",
       "0  Arsenal  Brighton          0          3  May 14, 2023, 6:30 PM  Andy Madley         8         6                   4                   7  Premier League Round 36 2022/2023"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363b1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = pd.concat([match, match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60afe326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pages(last_url):\n",
    "    curr = int(last_url[-2:]) ## assuming double digits\n",
    "    base = last_url[:len(last_url)-2]\n",
    "    urls = []\n",
    "    while (curr >= 0):\n",
    "        urls.append(last_url)\n",
    "        last_url = base+str(curr-1)\n",
    "        curr-=1\n",
    "    return urls\n",
    "\n",
    "def get_urls(url):\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Find all the match containers\n",
    "    match_containers = soup.find_all('div', class_='css-1fkfix2-LeagueMatchCSS e565gvj0')\n",
    "\n",
    "    # Initialize a list to store the href attributes\n",
    "    match_links = []\n",
    " \n",
    "    # Iterate through each match container and extract the href attribute\n",
    "    for match_container in match_containers:\n",
    "        match_link = match_container.find('a', href=True)\n",
    "        if match_link:\n",
    "            match_href = match_link['href']\n",
    "            match_links.append('https://www.fotmob.com'+match_href)\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Return the list of match href attributes\n",
    "    return match_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff614061",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls23 = create_pages('https://www.fotmob.com/leagues/47/matches/premier-league?season=2022-2023&page=33')\n",
    "urls22 = create_pages('https://www.fotmob.com/leagues/47/matches/premier-league?season=2021-2022&page=34')\n",
    "urls19 = create_pages('https://www.fotmob.com/leagues/47/matches/premier-league?season=2018-2019&page=35')\n",
    "urls18 = create_pages('https://www.fotmob.com/leagues/47/matches/premier-league?season=2017-2018&page=35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a69fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_links(season_pages):\n",
    "    links = []\n",
    "    for p in season_pages:\n",
    "        curr = get_urls(p)\n",
    "        links.extend(curr)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "link23 = get_season_links(urls23)\n",
    "link22 = get_season_links(urls22)\n",
    "link19 = get_season_links(urls19)\n",
    "test_urls = get_season_links(urls18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5047772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(links):\n",
    "    index = 0\n",
    "    df = pd.DataFrame()\n",
    "    for link in links:\n",
    "        while True:\n",
    "            try:\n",
    "                curr = scrape_match(link, index)\n",
    "                index+=1\n",
    "                df = pd.concat([df, curr])\n",
    "                break\n",
    "            except:\n",
    "                print('refreshing')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1962e",
   "metadata": {},
   "source": [
    "Sanity Check: we will use the create_table functino on a single match to see if everything works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2dd0e63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fc7b2c75b042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mepl23\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mepl23\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_table' is not defined"
     ]
    }
   ],
   "source": [
    "epl23 = create_table(link23)\n",
    "epl22 = create_table(link22)\n",
    "epl19 = create_table(link19)\n",
    "\n",
    "test = create_table(test_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474f7019",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epl23' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f6c498c3fdb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mepl23\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mepl23\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epl23' is not defined"
     ]
    }
   ],
   "source": [
    "epl23.to_csv(\"Epl23.csv\")\n",
    "epl22.to_csv(\"Epl22.csv\")\n",
    "epl19.to_csv(\"Epl19.csv\")\n",
    "\n",
    "test.to_csv('test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
